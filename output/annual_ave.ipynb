{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.font_manager import FontProperties\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.ticker as ticker\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from pandas import Series\n",
    "from netCDF4 import Dataset\n",
    "from netCDF4 import num2date\n",
    "from netCDF4 import date2num\n",
    "import datetime\n",
    "import os\n",
    "import sys\n",
    "import os.path\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Reading in model output files, from three different applications, fabm0d,\n",
    "# gotm1d and gotmlake\n",
    "output_dir= os.path.normpath(os.getcwd() + os.sep + os.pardir+\"/output\")\n",
    "fabm0d=['pclake-fabm0d-2m.nc','pclake-fabm0d-5m.nc','pclake-fabm0d-10m.nc','pclake-fabm0d-20m.nc']\n",
    "gotm1d=['pclake-gotm1d-2m.nc','pclake-gotm1d-5m.nc','pclake-gotm1d-10m.nc','pclake-gotm1d-20m.nc']\n",
    "gotmlake=['pclake-gotmlake-2m.nc','pclake-gotmlake-5m.nc','pclake-gotmlake-10m.nc','pclake-gotmlake-20m.nc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set ploting time intervals(keep matplotlib datetime format)\n",
    "# Since 3 applications has the same time intervals, so use anyone of them is fine\n",
    "# Set ploting time intervals(keep matplotlib datetime format)\n",
    "path=os.path.join(output_dir, fabm0d[0])\n",
    "# convert NetCDF data to Dataset, to read time\n",
    "time_nc=Dataset(path, mode='r')\n",
    "time        = time_nc.variables['time']\n",
    "units       = time_nc.variables['time'].units\n",
    "valid_times = num2date(time[:], units=units).tolist()\n",
    "# Set the start and stop point for ploting interval\n",
    "start=valid_times.index(datetime.datetime(2015, 1, 1))\n",
    "stop=valid_times.index(datetime.datetime(2016, 1, 1))\n",
    "# Time for extracting data\n",
    "time=valid_times[start:stop]\n",
    "# ploting x axis\n",
    "dt=datetime.date\n",
    "# Setting period, and model output intervals is 1day\n",
    "time_t=mdates.drange(dt(2015,1,1), dt(2016,1,1), datetime.timedelta(days=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read in gotm1d data, get the vertical avarage value, and store in nc Dataset form\n",
    "# creat dict for store output of wanted fabm0d data\n",
    "Tm_0d=[];PAR_0d=[];O2_0d=[];TN_0d=[];TP_0d=[];\n",
    "Phy_0d=[];Zoo_0d=[];Fish_0d=[]\n",
    "for f_0d in fabm0d:\n",
    "    path=os.path.join(output_dir, f_0d)\n",
    "    fabm0d_nc=Dataset(path, mode='r')\n",
    "# depths for calculating fish biomass\n",
    "    if f_0d=='pclake-fabm0d-2m.nc':\n",
    "        d=2.0\n",
    "    elif f_0d=='pclake-fabm0d-5m.nc':\n",
    "        d=5.0\n",
    "    elif f_0d=='pclake-fabm0d-10m.nc':\n",
    "        d=10.0\n",
    "    elif f_0d=='pclake-fabm0d-20m.nc':\n",
    "        d=20.0\n",
    "# create empty lists for storging extracted and treated variables\n",
    "    Tm   = fabm0d_nc.variables['temp'][start:stop,0,0]\n",
    "    PAR  = fabm0d_nc.variables['phytoplankton_water_partop'][start:stop,0,0]\n",
    "    O2   = fabm0d_nc.variables['abiotic_water_sO2W'][start:stop,0,0]\n",
    "    TN   = fabm0d_nc.variables['pclake_totN_calculator_result'][start:stop,0,0]\n",
    "    TP   = fabm0d_nc.variables['pclake_totP_calculator_result'][start:stop,0,0]\n",
    "    Phy  = fabm0d_nc.variables['phytoplankton_water_aDPhytW'][start:stop,0,0]\n",
    "    Zoo  = fabm0d_nc.variables['foodweb_water_sDZoo'][start:stop,0,0]\n",
    "    Fish = fabm0d_nc.variables['foodweb_water_sDFiAd'][start:stop,0,0]*d+ \\\n",
    "    fabm0d_nc.variables['foodweb_water_sDFiJv'][start:stop,0,0]*d\n",
    "# Get anually average values\n",
    "    Tm_0d.append(np.mean(Tm[:]))\n",
    "    PAR_0d.append(np.mean(PAR[:]))\n",
    "    O2_0d.append(np.mean(O2[:]))\n",
    "    TN_0d.append(np.mean(TN[:]))\n",
    "    TP_0d.append(np.mean(TP[:]))\n",
    "    Phy_0d.append(np.mean(Phy[:]))\n",
    "    Zoo_0d.append(np.mean(Zoo[:]))\n",
    "    Fish_0d.append(np.mean(Fish[:]))    \n",
    "Ave_0d = np.row_stack((Tm_0d,PAR_0d,O2_0d,TN_0d,TP_0d,Phy_0d,Zoo_0d,Fish_0d))\n",
    "df_0d  = DataFrame(Ave_0d,columns=['2m','5m','10m','20m'],index=['Tm','PAR','O2','TN','TP','Phy','Zoo','Fish'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Get gotm1d data\n",
    "Tm_1d_surf=[];Tm_1d_bott=[];Tm_1d_mean=[];\n",
    "PAR_1d_surf=[];PAR_1d_bott=[];PAR_1d_mean=[];\n",
    "O2_1d_surf=[];O2_1d_bott=[];O2_1d_mean=[];\n",
    "TN_1d_surf=[];TN_1d_bott=[];TN_1d_mean=[];\n",
    "TP_1d_surf=[];TP_1d_bott=[];TP_1d_mean=[];\n",
    "Phy_1d_surf=[];Phy_1d_bott=[];Phy_1d_mean=[];\n",
    "Zoo_1d_surf=[];Zoo_1d_bott=[];Zoo_1d_mean=[];\n",
    "Fish_1d_surf=[];Fish_1d_bott=[];Fish_1d_mean=[];\n",
    "for f_1d in gotm1d:\n",
    "    path=os.path.join(output_dir, f_1d)\n",
    "    gotm1d_nc=Dataset(path, mode='r')\n",
    "#   Get surface value   \n",
    "    Tm_surf   = gotm1d_nc.variables['temp'][start:stop,-1,0,0]\n",
    "    PAR_surf  = gotm1d_nc.variables['phytoplankton_water_partop'][start:stop,-1,0,0]\n",
    "    O2_surf   = gotm1d_nc.variables['abiotic_water_sO2W'][start:stop,-1,0,0]\n",
    "    TN_surf   = gotm1d_nc.variables['pclake_totN_calculator_result'][start:stop,-1,0,0]\n",
    "    TP_surf   = gotm1d_nc.variables['pclake_totP_calculator_result'][start:stop,-1,0,0]\n",
    "    Phy_surf  = gotm1d_nc.variables['phytoplankton_water_aDPhytW'][start:stop,-1,0,0]\n",
    "    Zoo_surf  = gotm1d_nc.variables['foodweb_water_sDZoo'][start:stop,-1,0,0]\n",
    "    Fish_surf = gotm1d_nc.variables['foodweb_water_sDFiAd'][start:stop,-1,0,0]*0.4 + \\\n",
    "                gotm1d_nc.variables['foodweb_water_sDFiJv'][start:stop,-1,0,0]*0.4    \n",
    "#   Get bottom value\n",
    "    Tm_bott   = gotm1d_nc.variables['temp'][start:stop,0,0,0]\n",
    "    PAR_bott  = gotm1d_nc.variables['phytoplankton_water_partop'][start:stop,0,0,0]\n",
    "    O2_bott   = gotm1d_nc.variables['abiotic_water_sO2W'][start:stop,0,0,0]\n",
    "    TN_bott   = gotm1d_nc.variables['pclake_totN_calculator_result'][start:stop,0,0,0]\n",
    "    TP_bott   = gotm1d_nc.variables['pclake_totP_calculator_result'][start:stop,0,0,0]\n",
    "    Phy_bott  = gotm1d_nc.variables['phytoplankton_water_aDPhytW'][start:stop,0,0,0]\n",
    "    Zoo_bott  = gotm1d_nc.variables['foodweb_water_sDZoo'][start:stop,0,0,0]\n",
    "    Fish_bott = gotm1d_nc.variables['foodweb_water_sDFiAd'][start:stop,0,0,0]*0.4 + \\\n",
    "                gotm1d_nc.variables['foodweb_water_sDFiJv'][start:stop,0,0,0]*0.4    \n",
    "#  Get vertical average    \n",
    "    Tm_mean=[];PAR_mean=[];O2_mean=[];TN_mean=[];TP_mean=[];Phy_mean=[];Zoo_mean=[];Fish_mean=[]\n",
    "    i=start\n",
    "    for t in time:\n",
    "        Tm_mean.append(np.mean(gotm1d_nc.variables['temp'][i,:,0,0]))\n",
    "        PAR_mean.append(np.mean(gotm1d_nc.variables['phytoplankton_water_partop'][i,:,0,0]))\n",
    "        O2_mean.append(np.mean(gotm1d_nc.variables['abiotic_water_sO2W'][i,:,0,0]))\n",
    "        TN_mean.append(np.mean(gotm1d_nc.variables['pclake_totN_calculator_result'][i,:,0,0]))\n",
    "        TP_mean.append(np.mean(gotm1d_nc.variables['pclake_totP_calculator_result'][i,:,0,0]))\n",
    "        Phy_mean.append(np.mean(gotm1d_nc.variables['phytoplankton_water_aDPhytW'][i,:,0,0]))\n",
    "        Zoo_mean.append(np.mean(gotm1d_nc.variables['foodweb_water_sDZoo'][i,:,0,0]))\n",
    "        Fish_mean.append(np.sum(gotm1d_nc.variables['foodweb_water_sDFiAd'][i,:,0,0]*0.4) + \\\n",
    "                    np.sum(gotm1d_nc.variables['foodweb_water_sDFiJv'][i,:,0,0]*0.4))\n",
    "        i=i+1\n",
    "        \n",
    "# Assemble surface variables\n",
    "    Tm_1d_surf.append(np.mean(Tm_surf[:]))\n",
    "    PAR_1d_surf.append(np.mean(PAR_surf[:]))\n",
    "    O2_1d_surf.append(np.mean(O2_surf[:]))\n",
    "    TN_1d_surf.append(np.mean(TN_surf[:]))\n",
    "    TP_1d_surf.append(np.mean(TP_surf[:]))\n",
    "    Phy_1d_surf.append(np.mean(Phy_surf[:]))\n",
    "    Zoo_1d_surf.append(np.mean(Zoo_surf[:]))\n",
    "    Fish_1d_surf.append(np.mean(Fish_surf[:]))\n",
    "    \n",
    "# Assemble bottom variables    \n",
    "    Tm_1d_bott.append(np.mean(Tm_bott[:])) \n",
    "    PAR_1d_bott.append(np.mean(PAR_bott[:]))\n",
    "    O2_1d_bott.append(np.mean(O2_bott[:]))\n",
    "    TN_1d_bott.append(np.mean(TN_bott[:]))\n",
    "    TP_1d_bott.append(np.mean(TP_bott[:]))\n",
    "    Phy_1d_bott.append(np.mean(Phy_bott[:]))\n",
    "    Zoo_1d_bott.append(np.mean(Zoo_bott[:]))\n",
    "    Fish_1d_bott.append(np.mean(Fish_bott[:]))\n",
    "# Assemble mean values\n",
    "    Tm_1d_mean.append(np.mean(Tm_mean[:]))\n",
    "    PAR_1d_mean.append(np.mean(PAR_mean[:]))\n",
    "    O2_1d_mean.append(np.mean(O2_mean[:]))\n",
    "    TN_1d_mean.append(np.mean(TN_mean[:]))    \n",
    "    TP_1d_mean.append(np.mean(TP_mean[:]))\n",
    "    Phy_1d_mean.append(np.mean(Phy_mean[:]))\n",
    "    Zoo_1d_mean.append(np.mean(Zoo_mean[:]))\n",
    "    Fish_1d_mean.append(np.mean(Fish_mean[:]))\n",
    "# Put three different layer together   \n",
    "Tm_1d= np.row_stack((Tm_1d_mean,Tm_1d_surf,Tm_1d_bott))\n",
    "PAR_1d= np.row_stack((PAR_1d_mean,PAR_1d_surf,PAR_1d_bott))\n",
    "O2_1d= np.row_stack((O2_1d_mean,O2_1d_surf,O2_1d_bott))\n",
    "TN_1d= np.row_stack((TN_1d_mean,TN_1d_surf,TN_1d_bott))\n",
    "TP_1d= np.row_stack((TP_1d_mean,TP_1d_surf,TP_1d_bott))    \n",
    "Phy_1d= np.row_stack((Phy_1d_mean,Phy_1d_surf,Phy_1d_bott))\n",
    "Zoo_1d= np.row_stack((Zoo_1d_mean,Zoo_1d_surf,Zoo_1d_bott))\n",
    "Fish_1d= np.row_stack((Fish_1d_mean,Fish_1d_surf,Fish_1d_bott))\n",
    "\n",
    "# assemble all data together\n",
    "Ave_1d = np.row_stack((Tm_1d,PAR_1d,O2_1d,TN_1d,TP_1d,Phy_1d,Zoo_1d,Fish_1d))\n",
    "df_1d  = DataFrame(Ave_1d,columns=['2m','5m','10m','20m'],index=['Tm_','Tm_surf','Tm_bott',\n",
    "                                                                 'PAR','PAR_surf','PAR_bott',\n",
    "                                                                 'O2','O2_surf','O2_bott',\n",
    "                                                                 'TN','TN_surf','TN_bott',\n",
    "                                                                 'TP','TP_surf','TP_bott',\n",
    "                                                                 'Phy','Phy_surf','Phy_bott',\n",
    "                                                                 'Zoo','Zoo_surf','Zoo_bott',\n",
    "                                                                 'Fish','Fish_surf','Fish_bott'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get gotmlake data\n",
    "Tm_lake_surf=[];Tm_lake_bott=[];Tm_lake_mean=[];\n",
    "PAR_lake_surf=[];PAR_lake_bott=[];PAR_lake_mean=[];\n",
    "O2_lake_surf=[];O2_lake_bott=[];O2_lake_mean=[];\n",
    "TN_lake_surf=[];TN_lake_bott=[];TN_lake_mean=[];\n",
    "TP_lake_surf=[];TP_lake_bott=[];TP_lake_mean=[];\n",
    "Phy_lake_surf=[];Phy_lake_bott=[];Phy_lake_mean=[];\n",
    "Zoo_lake_surf=[];Zoo_lake_bott=[];Zoo_lake_mean=[];\n",
    "Fish_lake_surf=[];Fish_lake_bott=[];Fish_lake_mean=[];\n",
    "# Get the volumn fraction for each depth in gotmlake\n",
    "# calculated according to hypsograph data in excel.\n",
    "f_Vn_2m=[0.04,0.12,0.20,0.28,0.36]\n",
    "f_Vn_5m=[0.01,0.02,0.03,0.04,0.05,0.07,0.08,0.09,0.10,0.11,0.12,0.13,0.15]\n",
    "f_Vn_10m=[0.0025,0.0056,0.0087,0.0119,0.0150,0.0181,0.0212,0.0244,0.0275,\n",
    "          0.0306,0.0337,0.0369,0.0400,0.0431,0.0463,0.0494,0.0525,0.0556,\n",
    "          0.0588,0.0619,0.0650,0.0681,0.0713,0.0744,0.0775]\n",
    "f_Vn_20m=[0.000854443,0.001635895,0.002417346,0.003198797,0.003980249,0.0047617,\n",
    "          0.005543151,0.006324602,0.007106054,0.007887505,0.008668956,0.009450408,\n",
    "          0.010231859,0.01101331,0.011794761,0.012576213,0.013357664,0.014139115,\n",
    "          0.014920567,0.015702018,0.016483469,0.01726492,0.018046372,0.018827823,\n",
    "          0.019609274,0.020390726,0.021172177,0.021953628,0.02273508,0.023516531,\n",
    "          0.024297982,0.025079433,0.025860885,0.026642336,0.027423787,0.028205239,\n",
    "          0.02898669,0.029768141,0.030549592,0.031331044,0.032112495,0.032893946,\n",
    "          0.033675398,0.034456849,0.0352383,0.036019751,0.036801203,0.037582654,\n",
    "          0.038364105,0.039145557]\n",
    "\n",
    "\n",
    "for f_lake in gotmlake:\n",
    "    path=os.path.join(output_dir, f_lake)\n",
    "    gotmlake_nc=Dataset(path, mode='r')\n",
    "    # Get the f_lvl for different depth\n",
    "    lvl=len(gotmlake_nc.variables['temp'][0])\n",
    "    if lvl==5:\n",
    "        f_lvl=f_Vn_2m\n",
    "    elif lvl== 13:\n",
    "        f_lvl=f_Vn_5m\n",
    "    elif lvl==25:\n",
    "        f_lvl=f_Vn_10m\n",
    "    elif lvl==50:\n",
    "        f_lvl=f_Vn_20m\n",
    "#   Get surface value   \n",
    "    Tm_surf   = gotmlake_nc.variables['temp'][start:stop,-1,0,0]\n",
    "    PAR_surf  = gotmlake_nc.variables['phytoplankton_water_partop'][start:stop,-1,0,0]\n",
    "    O2_surf   = gotmlake_nc.variables['abiotic_water_sO2W'][start:stop,-1,0,0]\n",
    "    TN_surf   = gotmlake_nc.variables['pclake_totN_calculator_result'][start:stop,-1,0,0]\n",
    "    TP_surf   = gotmlake_nc.variables['pclake_totP_calculator_result'][start:stop,-1,0,0]\n",
    "    Phy_surf  = gotmlake_nc.variables['phytoplankton_water_aDPhytW'][start:stop,-1,0,0]\n",
    "    Zoo_surf  = gotmlake_nc.variables['foodweb_water_sDZoo'][start:stop,-1,0,0]\n",
    "    Fish_surf = gotmlake_nc.variables['foodweb_water_sDFiAd'][start:stop,-1,0,0]*0.4 + \\\n",
    "                gotmlake_nc.variables['foodweb_water_sDFiJv'][start:stop,-1,0,0]*0.4    \n",
    "#   Get bottom value\n",
    "    Tm_bott   = gotmlake_nc.variables['temp'][start:stop,0,0,0]\n",
    "    PAR_bott  = gotmlake_nc.variables['phytoplankton_water_partop'][start:stop,0,0,0]\n",
    "    O2_bott   = gotmlake_nc.variables['abiotic_water_sO2W'][start:stop,0,0,0]\n",
    "    TN_bott   = gotmlake_nc.variables['pclake_totN_calculator_result'][start:stop,0,0,0]\n",
    "    TP_bott   = gotmlake_nc.variables['pclake_totP_calculator_result'][start:stop,0,0,0]\n",
    "    Phy_bott  = gotmlake_nc.variables['phytoplankton_water_aDPhytW'][start:stop,0,0,0]\n",
    "    Zoo_bott  = gotmlake_nc.variables['foodweb_water_sDZoo'][start:stop,0,0,0]\n",
    "    Fish_bott = gotmlake_nc.variables['foodweb_water_sDFiAd'][start:stop,0,0,0]*0.4 + \\\n",
    "                gotmlake_nc.variables['foodweb_water_sDFiJv'][start:stop,0,0,0]*0.4    \n",
    "#  Get vertical wieghted average       \n",
    "    Tm_mean=[];PAR_mean=[];O2_mean=[];TN_mean=[];TP_mean=[];Phy_mean=[];Zoo_mean=[];Fish_mean=[]\n",
    "    i=start\n",
    "    for t in time:\n",
    "        Tm_mean.append(np.sum(gotmlake_nc.variables['temp'][i,:,0,0]*f_lvl[:]))\n",
    "        PAR_mean.append(np.sum(gotmlake_nc.variables['phytoplankton_water_partop'][i,:,0,0]*f_lvl[:]))\n",
    "        O2_mean.append(np.sum(gotmlake_nc.variables['abiotic_water_sO2W'][i,:,0,0]*f_lvl[:]))\n",
    "        TN_mean.append(np.sum(gotmlake_nc.variables['pclake_totN_calculator_result'][i,:,0,0]*f_lvl[:]))\n",
    "        TP_mean.append(np.sum(gotmlake_nc.variables['pclake_totP_calculator_result'][i,:,0,0]*f_lvl[:]))\n",
    "        Phy_mean.append(np.sum(gotmlake_nc.variables['phytoplankton_water_aDPhytW'][i,:,0,0]*f_lvl[:]))\n",
    "        Zoo_mean.append(np.sum(gotmlake_nc.variables['foodweb_water_sDZoo'][i,:,0,0]*f_lvl[:]))\n",
    "        Fish_mean.append(np.sum(gotmlake_nc.variables['foodweb_water_sDFiAd'][i,:,0,0]*0.4) + \\\n",
    "                    np.sum(gotmlake_nc.variables['foodweb_water_sDFiJv'][i,:,0,0]*0.4))\n",
    "        i=i+1\n",
    "# Assemble surface variables\n",
    "    Tm_lake_surf.append(np.mean(Tm_surf[:]))\n",
    "    PAR_lake_surf.append(np.mean(PAR_surf[:]))\n",
    "    O2_lake_surf.append(np.mean(O2_surf[:]))\n",
    "    TN_lake_surf.append(np.mean(TN_surf[:]))\n",
    "    TP_lake_surf.append(np.mean(TP_surf[:]))\n",
    "    Phy_lake_surf.append(np.mean(Phy_surf[:]))\n",
    "    Zoo_lake_surf.append(np.mean(Zoo_surf[:]))\n",
    "    Fish_lake_surf.append(np.mean(Fish_surf[:]))\n",
    "    \n",
    "# Assemble bottom variables    \n",
    "    Tm_lake_bott.append(np.mean(Tm_bott[:])) \n",
    "    PAR_lake_bott.append(np.mean(PAR_bott[:]))\n",
    "    O2_lake_bott.append(np.mean(O2_bott[:]))\n",
    "    TN_lake_bott.append(np.mean(TN_bott[:]))\n",
    "    TP_lake_bott.append(np.mean(TP_bott[:]))\n",
    "    Phy_lake_bott.append(np.mean(Phy_bott[:]))\n",
    "    Zoo_lake_bott.append(np.mean(Zoo_bott[:]))\n",
    "    Fish_lake_bott.append(np.mean(Fish_bott[:]))\n",
    "# Assemble mean values\n",
    "    Tm_lake_mean.append(np.mean(Tm_mean[:]))\n",
    "    PAR_lake_mean.append(np.mean(PAR_mean[:]))\n",
    "    O2_lake_mean.append(np.mean(O2_mean[:]))\n",
    "    TN_lake_mean.append(np.mean(TN_mean[:]))    \n",
    "    TP_lake_mean.append(np.mean(TP_mean[:]))\n",
    "    Phy_lake_mean.append(np.mean(Phy_mean[:]))\n",
    "    Zoo_lake_mean.append(np.mean(Zoo_mean[:]))\n",
    "    Fish_lake_mean.append(np.mean(Fish_mean[:]))\n",
    "        \n",
    "        \n",
    "# Put three different layer together   \n",
    "Tm_lake= np.row_stack((Tm_lake_mean,Tm_lake_surf,Tm_lake_bott))\n",
    "PAR_lake= np.row_stack((PAR_lake_mean,PAR_lake_surf,PAR_lake_bott))\n",
    "O2_lake= np.row_stack((O2_lake_mean,O2_lake_surf,O2_lake_bott))\n",
    "TN_lake= np.row_stack((TN_lake_mean,TN_lake_surf,TN_lake_bott))\n",
    "TP_lake= np.row_stack((TP_lake_mean,TP_lake_surf,TP_lake_bott))    \n",
    "Phy_lake= np.row_stack((Phy_lake_mean,Phy_lake_surf,Phy_lake_bott))\n",
    "Zoo_lake= np.row_stack((Zoo_lake_mean,Zoo_lake_surf,Zoo_lake_bott))\n",
    "Fish_lake= np.row_stack((Fish_lake_mean,Fish_lake_surf,Fish_lake_bott))\n",
    "\n",
    "# assemble all data together\n",
    "Ave_lake = np.row_stack((Tm_lake,PAR_lake,O2_lake,TN_lake,TP_lake,Phy_lake,Zoo_lake,Fish_lake))\n",
    "df_lake  = DataFrame(Ave_lake,columns=['2m','5m','10m','20m'],index=['Tm','Tm_surf','Tm_bott',\n",
    "                                                                 'PAR','PAR_surf','PAR_bott',\n",
    "                                                                 'O2','O2_surf','O2_bott',\n",
    "                                                                 'TN','TN_surf','TN_bott',\n",
    "                                                                 'TP','TP_surf','TP_bott',\n",
    "                                                                 'Phy','Phy_surf','Phy_bott',\n",
    "                                                                 'Zoo','Zoo_surf','Zoo_bott',\n",
    "                                                                 'Fish','Fish_surf','Fish_bott'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Re-structure data\n",
    "sum_2m =  pd.concat([df_0d.loc[:,'2m'],df_1d.loc[:,'2m'],df_lake.loc[:,'2m']],axis=1,keys=['0d','1d','lake'])\n",
    "sum_5m =  pd.concat([df_0d.loc[:,'5m'],df_1d.loc[:,'5m'],df_lake.loc[:,'5m']],axis=1,keys=['0d','1d','lake'])\n",
    "sum_10m =  pd.concat([df_0d.loc[:,'10m'],df_1d.loc[:,'10m'],df_lake.loc[:,'10m']],axis=1,keys=['0d','1d','lake'])\n",
    "sum_20m =  pd.concat([df_0d.loc[:,'20m'],df_1d.loc[:,'20m'],df_lake.loc[:,'20m']],axis=1,keys=['0d','1d','lake'])\n",
    "#pd.concat([df_0d.loc[:,'2m'],df_1d.loc[:,'2m'],df_lake.loc[:,'2m']],axis=1,keys=['0d','1d','lake'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Total_annual=pd.concat([sum_2m,sum_5m,sum_10m,sum_20m],axis=1,keys=['2m','5m','10m','20m'])\n",
    "Total_annual.to_csv('Annual_averag.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/fenjuan/BIOS/Lakes/pclaketest/output\n"
     ]
    }
   ],
   "source": [
    "cd pclaketest/output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
